{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from course_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca51859",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 18 â€“ Classifier Evaluation, Model Fairness, Parting Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2236228-4ade-4ecf-a59a-7944e6b4ea40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision and recall\n",
    "\n",
    "<center><img src=\"imgs/Precisionrecall.svg.png\" width=30%></center>\n",
    "\n",
    "<center>(<a href=\"https://en.wikipedia.org/wiki/Precision_and_recall\">source</a>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3304b7ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤” </h3>\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "After fitting a `BillyClassifier`, we use it to make predictions on an unseen test set. Our results are summarized in the following confusion matrix.\n",
    "\n",
    "| | **Predicted Negative** | **Predicted Positive** |\n",
    "| --- | --- | --- |\n",
    "| **Actually Negative** | ??? | 30 |\n",
    "| **Actually Positive** | 66 | 105 |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c51369",
   "metadata": {},
   "source": [
    "**Part 1**: What is the recall of our classifier? Give your answer as a fraction (it does not need to be simplified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a87e9e-e1dd-48e8-b259-4fcb872f137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 105 / (105 + 66) = 105 / 171"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f2082",
   "metadata": {},
   "source": [
    "**Part 2**: The accuracy of our classifier is $\\frac{69}{117}$. How many **true negatives** did our classifier have? Give your answer as an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af451355-8a56-49b5-a7af-bfcf98dc2055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x + 105) / (x + 201) = 138 / 234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7271ae-ab84-46b7-867e-e11b3ed44c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59eb5fe",
   "metadata": {},
   "source": [
    "**Part 3**: True or False: In order for a binary classifier's precision and recall to be equal, the number of mistakes it makes must be an even number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8972dc-019b-4d6c-b500-17f28036ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP / (TP + FP) = TP / (TP + FN)\n",
    "# TP + FP = TP + FN\n",
    "# FP = FN\n",
    "# \n",
    "# FP + FP = 2 * FP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c092826",
   "metadata": {},
   "source": [
    "**Part 4**: Suppose we are building a classifier that listens to an audio source (say, from your phoneâ€™s microphone) and predicts whether or not it is Soulja Boyâ€™s 2008 classic â€œKiss Me thru the Phone.\" Our classifier is pretty good at detecting when the input stream is â€Kiss Me thru the Phone\", but it often incorrectly predicts that similar sounding songs are also â€œKiss Me thru the Phone.\"\n",
    "\n",
    "Complete the sentence: Our classifier has...\n",
    "- low precision and low recall.\n",
    "- low precision and high recall.\n",
    "- high precision and low recall.\n",
    "- high precision and high recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc7931",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80f041",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Wisconsin breast cancer dataset\n",
    "\n",
    "The Wisconsin breast cancer dataset (WBCD) is a commonly-used dataset for demonstrating binary classification. It is built into `sklearn.datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1145e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "loaded = load_breast_cancer() # explore the value of `loaded`!\n",
    "data = loaded['data']\n",
    "labels = 1 - loaded['target']\n",
    "cols = loaded['feature_names']\n",
    "bc = pd.DataFrame(data, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa367d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710aa827",
   "metadata": {},
   "source": [
    "1 stands for \"malignant\", i.e. cancerous, and 0 stands for \"benign\", i.e. safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241acd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(labels).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe9596e",
   "metadata": {},
   "source": [
    "Our goal is to use the features in `bc` to predict `labels`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040e76be",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic regression\n",
    "\n",
    "Logistic _regression_ is a linear _classification_ technique that builds upon linear regression. It models **the probability of belonging to class 1, given a feature vector**:\n",
    "\n",
    "$$P(y = 1 | \\vec{x}) = \\sigma (\\underbrace{w_0 + w_1 x^{(1)} + w_2 x^{(2)} + ... + w_d x^{(d)}}_{\\text{linear regression model}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787027bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here, $\\sigma(t) = \\frac{1}{1 + e^{-t}}$ is the **sigmoid** function; its outputs are between 0 and 1 (which means they can be interpreted as probabilities)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6617f05",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "ðŸ¤” **Question**: Suppose our logistic regression model predicts the probability that a tumor is malignant is 0.75. What class do we predict â€“ malignant or benign? What if the predicted probability is 0.3?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb6ec8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "ðŸ™‹ **Answer**: We have to pick a threshold (e.g. 0.5)!\n",
    "- If the predicted probability is above the threshold, we predict malignant (1).\n",
    "- Otherwise, we predict benign (0).\n",
    "- In practice, we use cross validation to decide this threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3887f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fitting a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310e8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e32901",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bc, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6486deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7672cba",
   "metadata": {},
   "source": [
    "How did `clf` come up with 1s and 0s?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e4bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae4b20",
   "metadata": {},
   "source": [
    "It turns out that the predicted labels come from applying a **threshold** of 0.5 to the predicted probabilities. We can access the predicted probabilities using the `predict_proba` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b47bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [:, 1] refers to the predicted probabilities for class 1.\n",
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18585288",
   "metadata": {},
   "source": [
    "Note that our model still has $w^*$s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a20536",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eccc315",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluating our model\n",
    "\n",
    "Let's see how well our model does on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f581932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3df1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f6b3e",
   "metadata": {},
   "source": [
    "Which metric is more important for this task â€“ precision or recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee157da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test);\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b440311",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f392d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What if we choose a different threshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d1e787",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "ðŸ¤” **Question**: Suppose we choose a threshold **higher** than 0.5. What will happen to our model's precision and recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc9f2ab",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "ðŸ™‹ **Answer**: Precision will increase, while recall will decrease*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703d59c8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If the \"bar\" is higher to predict 1, then we will have fewer positives in general, and thus fewer false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac3a66e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The denominator in $\\text{precision} = \\frac{TP}{TP + FP}$ will get smaller, and so precision will increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ab1dee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- However, the number of false negatives will increase, as we are being more \"strict\" about what we classify as positive, and so $\\text{recall} = \\frac{TP}{TP + FN}$ will decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63eb82e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- *It is possible for either or both to stay the same, if changing the threshold slightly (e.g. from 0.5 to 0.500001) doesn't change any predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b90c7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Similarly, if we decrease our threshold, our model's precision will decrease, while its recall will increase. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188e3d78",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Trying several thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6d3d6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The classification threshold is not actually a hyperparameter of `LogisticRegression`, because the threshold doesn't change the coefficients ($w^*$s) of the logistic regression model itself (see [this article](https://stats.stackexchange.com/questions/390186/is-decision-threshold-a-hyperparameter-in-logistic-regression#:~:text=The%20decision%20threshold%20is%20not,how%20hyper%2Dparameters%20are%20tuned.) for more details).\n",
    "\n",
    "- Still, the threshold affects our decision rule, so we can tune it using cross-validation (which is not what we're doing below).\n",
    "- It's also useful to plot how our metrics change as we change the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.01, 1.01, 0.01)\n",
    "precisions = np.array([])\n",
    "recalls = np.array([])\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = clf.predict_proba(X_test)[:, 1] >= t\n",
    "    precisions = np.append(precisions, metrics.precision_score(y_test, y_pred, zero_division=1))\n",
    "    recalls = np.append(recalls, metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3931101",
   "metadata": {},
   "source": [
    "Let's visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a456fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x=thresholds, y=precisions,\n",
    "        labels={'x': 'Threshold', 'y': 'Precision'}, title='Precision vs. Threshold', width=600, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ab0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x=thresholds, y=recalls, \n",
    "        labels={'x': 'Threshold', 'y': 'Recall'}, title='Recall vs. Threshold', width=600, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2028a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x=recalls, y=precisions, hover_name=thresholds, \n",
    "        labels={'x': 'Recall', 'y': 'Precision'}, title='Precision vs. Recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e90bd5",
   "metadata": {},
   "source": [
    "The above curve is called a precision-recall (or PR) curve.\n",
    "\n",
    "ðŸ¤” **Question**: Based on the PR curve above, what threshold would you choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4830792b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Combining precision and recall\n",
    "\n",
    "If we care equally about a model's precision $PR$ and recall $RE$, we can combine the two using a single metric called the **F1-score**:\n",
    "\n",
    "$$\\text{F1-score} = \\text{harmonic mean}(PR, RE) = 2\\frac{PR \\cdot RE}{PR + RE}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53d0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = metrics.precision_score(y_test, clf.predict(X_test))\n",
    "re = metrics.recall_score(y_test, clf.predict(X_test))\n",
    "\n",
    "2 * pr * re / (pr + re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec6703",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e120d7",
   "metadata": {},
   "source": [
    "Both F1-score and accuracy are overall measures of a binary classifier's performance. But remember, accuracy is misleading in the presence of class imbalance, and doesn't take into account the kinds of errors the classifier makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9060948",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc2323",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other evaluation metrics for binary classifiers\n",
    "\n",
    "We just scratched the surface! This [excellent table from Wikipedia](https://en.wikipedia.org/wiki/Template:Diagnostic_testing_diagram) summarizes the many other metrics that exist.\n",
    "\n",
    "<center><img src='imgs/wiki-table.png' width=75%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac429208",
   "metadata": {},
   "source": [
    "If you're interested in exploring further, a good next metric to look at is **true negative rate (i.e. specificity)**, which is the analogue of recall for true negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaaf33f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd4172",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fairness: why do we care?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be875eb2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Sometimes, a model performs better for certain groups than others; in such cases we say the model is **unfair**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f91ad33",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since ML models are now used in processes that significantly affect human lives, it is important that they are fair!\n",
    "    * Job applications and college admissions.\n",
    "    * Criminal sentencing and parole grants.\n",
    "    * Predictive policing.\n",
    "    * Credit and loans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db21b8c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df96f7de",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We'd like to build a model that is _fair_, meaning that it performs the same for individuals within a group and individuals outside of the group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd476007",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What do we mean by \"perform\"? What do we mean by \"the same\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d1e1c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"imgs/parity.png\" width=900></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5729f2d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parity measures for classifiers\n",
    "\n",
    "Suppose $C$ is a classifier we've already trained, and $A$ is some binary attribute that denotes whether an individual is a member of a _sensitive_ group â€“ that is, a group we want to avoid discrimination for (e.g. $A = \\text{age is less than 25}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc8898",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $C$ achieves **accuracy parity** if $C$ has the same accuracy for individuals in $A$ and individuals not in $A$.\n",
    "    - **Example**: $C$ is a binary classifier that determines whether someone receives a loan.\n",
    "        - If the classifier predicts correctly, then either $C$ approves the loan and it is paid off, or $C$ denies the loan and it would have defaulted.\n",
    "        - If $C$ achieves accuracy parity, then the proportion of correctly classified loans should be the same for those under 25 and those over 25."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb35b231",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $C$ achieves **precision (or recall) parity** if $C$ has the same precision (or recall) for individuals in $A$ and individuals not in $A$.\n",
    "    - Recall parity is often called \"true positive rate parity.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b96a662",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $C$ achieves **demographic parity** if the proportion of predictions that are positive is equal for individuals in $A$ and individuals not in $A$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6278f32f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- With the exception of demographic parity, the parity measures above all involve checking whether some evaluation metric from Lecture 17 is equal across two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9472a8e5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More on parity measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293ac7ff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Which parity metric should you care about? It depends on your specific dataset and what types of errors are important!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f308ea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Many of these parity measures are **impossible** to satisfy simultaneously!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da27bc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The classifier parity metrics mentioned on the previous slide are only a few of the many possible parity metrics. See these [fairness notes](https://afraenkel.github.io/fairness-book/content/05-parity-measures.html) for more details, including more formal explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd17eb52",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- These don't apply for regression models; for those, we may care about **RMSE parity** or **$R^2$ parity**. There is also a notion of demographic parity for regression models, but it is outside of the scope of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8133fdef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Loan approval\n",
    "\n",
    "As you know from Project 2, LendingClub was a \"peer-to-peer lending company\"; they [used to publish](https://www.lendingclub.com/info/download-data.action) a dataset describing the loans that they approved.\n",
    "\n",
    "* `'tag'`: whether loan was repaid in full (1.0) or defaulted (0.0).\n",
    "* `'loan_amnt'`: amount of the loan in dollars.\n",
    "* `'emp_length'`: number of years employed.\n",
    "* `'home_ownership'`: whether borrower owns (1.0) or rents (0.0).\n",
    "* `'inq_last_6mths'`: number of credit inquiries in last six months.\n",
    "* `'revol_bal'`: revolving balance on borrows accounts.\n",
    "* `'age'`: age in years of the borrower (protected attribute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fcfa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.read_csv(Path('data') / 'loan_vars1.csv', index_col=0)\n",
    "loans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193ad90",
   "metadata": {},
   "source": [
    "The total amount of money loaned was over 5 billion dollars! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33148e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['loan_amnt'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe0f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9038ba67",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting `'tag'`\n",
    "\n",
    "Let's build a classifier that predicts whether or not a loan was paid in full. If we were a bank, we could use our trained classifier to determine whether to approve someone for a loan!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccccaba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb552ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loans.drop('tag', axis=1)\n",
    "y = loans.tag\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f85d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c1ce4",
   "metadata": {},
   "source": [
    "Recall, a prediction of 1 means that we predict that the loan will be paid in full."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da802548",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78523b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d46754",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test);\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89367ce0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision\n",
    "\n",
    "$$\\text{precision} = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "Precision describes the **proportion of loans that were approved that would have been paid back**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fbde48",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4738e246",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we subtract the precision from 1, we get the proportion of loans that were approved that **would not** have been paid back. This is known as the **false discovery rate**.\n",
    "\n",
    "$$\\frac{FP}{TP + FP} = 1 - \\text{precision}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8288253",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - metrics.precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920473c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall\n",
    "\n",
    "$$\\text{recall} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "Recall describes the **proportion of loans that would have been paid back that were actually approved**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e738e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f30a3a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we subtract the recall from 1, we get the proportion of loans that would have been paid back that **were denied**. This is known as the **false negative rate**.\n",
    "\n",
    "$$\\frac{FN}{TP + FN} = 1 - \\text{recall}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8492096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - metrics.recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0380f3d0",
   "metadata": {},
   "source": [
    "From both the perspective of the bank and the lendee, a high false negative rate is bad!\n",
    "- The bank left money on the table â€“ the lendee would have paid back the loan, but they weren't approved for a loan.\n",
    "- The lendee deserved the loan, but weren't given one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca9139",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### False negative rate by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b9e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = X_test\n",
    "results['age_bracket'] = results['age'].apply(lambda x: 5 * (x // 5 + 1))\n",
    "results['prediction'] = y_pred\n",
    "results['tag'] = y_test\n",
    "\n",
    "(\n",
    "    results\n",
    "    .groupby('age_bracket')\n",
    "    [['tag', 'prediction']]\n",
    "    .apply(lambda x: 1 - metrics.recall_score(x['tag'], x['prediction']))\n",
    "    .plot(kind='bar', title='False Negative Rate by Age Group')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ac6d9a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing parity measures\n",
    "\n",
    "- $C$: Our random forest classifier (1 if we approved the loan, 0 if we denied it).\n",
    "- $A$: Whether or not they were under 25 (1 if under, 0 if above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['is_young'] = (results['age'] < 25).replace({True: 'young', False: 'old'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028b388",
   "metadata": {},
   "source": [
    "First, let's compute the proportion of loans that were approved in each group. If these two numbers are the same, $C$ achieves demographic parity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bda10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby('is_young')['prediction'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfd587f",
   "metadata": {},
   "source": [
    "$C$ evidently does not achieve demographic parity â€“ older people are approved for loans far more often! Note that this doesn't factor in whether they were _correctly_ approved or _incorrectly_ approved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea011ada",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, let's compute the accuracy of $C$ in each group. If these two numbers are the same, $C$ achieves accuracy parity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a270863",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_accuracy = lambda x: metrics.accuracy_score(x['tag'], x['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff7797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    results\n",
    "    .groupby('is_young')\n",
    "    [['tag', 'prediction']]\n",
    "    .apply(compute_accuracy)\n",
    "    .rename('accuracy')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6cddc",
   "metadata": {},
   "source": [
    "Hmm... These numbers look much more similar than before!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4eb148",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Is this difference in accuracy significant?\n",
    "\n",
    "Let's run a **permutation test** to see if the difference in accuracy is significant.\n",
    "- **Null Hypothesis**: The classifier's accuracy is the same for both young people and old people, and any differences are due to chance.\n",
    "- **Alternative Hypothesis**: The classifier's accuracy is higher for old people.\n",
    "- Test statistic: Difference in accuracy (young minus old).\n",
    "- Significance level: 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = (results\n",
    "       .groupby('is_young')\n",
    "       [['tag', 'prediction']]\n",
    "       .apply(compute_accuracy)\n",
    "       .diff()\n",
    "       .iloc[-1])\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb4b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_in_acc = []\n",
    "for _ in range(500):\n",
    "    s = (\n",
    "        results[['is_young', 'prediction', 'tag']]\n",
    "        .assign(is_young=np.random.permutation(results['is_young']))\n",
    "        .groupby('is_young')\n",
    "        [['tag', 'prediction']]\n",
    "        .apply(compute_accuracy)\n",
    "        .diff()\n",
    "        .iloc[-1]\n",
    "    )\n",
    "    \n",
    "    diff_in_acc.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pd.Series(diff_in_acc).plot(kind='hist', histnorm='probability', nbins=20,\n",
    "                            title='Difference in Accuracy (Young - Old)')\n",
    "fig.add_vline(x=obs, line_color='red')\n",
    "fig.update_layout(xaxis_range=[-0.1, 0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b781a",
   "metadata": {},
   "source": [
    "It seems like the difference in accuracy across the two groups **is significant**, despite being only ~5%. Thus, $C$ likely does not achieve accuracy parity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e001ad2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ethical questions of fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fd113d-3da0-40bc-892c-b42950243f69",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤” </h3>\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e61db6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: Is it \"fair\" to deny loans to younger people at a higher rate?\n",
    "- Make an argument for \"yes\", then make an argument for \"no\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d913a7e-4a50-40c0-936c-8d93ed7c5e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes: from the bank, i want to make money\n",
    "# no:  from the government, i don't want to discourage young people from potential innovations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefd7962",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Federal law prevents age from being used as a determining factor in denying a loan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c030f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Not only should we use `'age'` to determine whether or not to approve a loan, but we also shouldn't use other features that are strongly correlated with `'age'`, like `'emp_length'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf9bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84507089-fec4-4654-8265-fb9595289dd2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parting Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637005a9-0a15-45e0-aac3-f828652f5f73",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"imgs/ds-lifecycle.svg\" width=\"40%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d214266-113d-4fbc-98c8-82bf5d73828a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Course goals âœ…\n",
    "\n",
    "In this course, you...\n",
    "\n",
    "* **Practiced** translating potentially vague questions into quantitative questions about measurable observations.\n",
    "* **Learned** to reason about 'black-box' processes (e.g. complicated models).\n",
    "* **Understood** computational and statistical implications of working with data.\n",
    "* **Learned** to use real data tools (e.g. love the documentation!).\n",
    "* **Got** a taste of the \"life of a data scientist\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ec0042-8b0e-4811-b574-4c2248fe6aa3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Course outcomes âœ…\n",
    "\n",
    "Now, you...\n",
    "\n",
    "* Are **prepared** for internships and data science \"take home\" interviews!\n",
    "* Are **ready** to create your own portfolio of personal projects.\n",
    "* Have the **background** and **maturity** to succeed in more advanced courses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0275d3f-b7aa-4ea3-9145-76320d02516e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Topics covered âœ…\n",
    "\n",
    "We learnt a lot this quarter.\n",
    "\n",
    "- Week 1: From BabyPandas to Pandas\n",
    "- Week 2: DataFrames\n",
    "- Week 3: Messy Data, Hypothesis Testing\n",
    "- Week 4: Missing Values and Imputation\n",
    "- Week 5: HTTP\n",
    "- Week 6: Web Scraping, Regex\n",
    "- Week 7: Text Features, Regression\n",
    "- Week 8: Feature Engineering\n",
    "- Week 9: Generalization, CV, Decision Trees\n",
    "- Week 10: Random Forests, Classifier Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbfd237-1f26-4526-985e-4c04934b8aac",
   "metadata": {},
   "source": [
    "### Good luck on your Final Projects and beyond!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
